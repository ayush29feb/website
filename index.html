<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>Ayush Saraf</title>

    <meta name="author" content="Ayush Saraf" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>" />
  </head>

  <body>
    <table style="width: 100%; max-width: 800px; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
      <tbody>
        <tr style="padding: 0px;">
          <td style="padding: 0px;">
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr style="padding: 0px;">
                  <td style="padding: 2.5%; width: 63%; vertical-align: middle;">
                    <p class="name" style="text-align: center;">
                      Ayush Saraf
                    </p>
                    <p>I am a Staff Software Engineer at <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a> in New York, where I work on Hyperscape and 3D world generation. My goal is to give people creative tools to build awesome 3D worlds‚Äîfrom capturing real spaces to creating fantastical imaginary worlds and everything in between.</p>
                    <p style="text-align: center;">
                      <a href="mailto:ayush29f@gmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=bluhHm8AAAAJ&hl=en">Google Scholar</a>
                      &nbsp;/&nbsp;
                      <a href="https://twitter.com/ayush29feb">Twitter</a> &nbsp;/&nbsp;
                      <a href="https://github.com/ayush29feb/">Github</a>
                    </p>
                  </td>
                  <td style="padding: 2.5%; width: 40%; max-width: 40%;">
                    <a href="images/ayush.png"><img style="width: 100%; max-width: 100%;" alt="profile photo" src="images/ayush.png" class="hoverZoomLink" /></a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <h2>Hyperscape</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;" bgcolor="#ffffd0">
              <tbody>
                <!-- Hyperscape Featured Video -->
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <video width="100%" style="max-width: 800px;" muted autoplay loop controls>
                      <source src="images/hyperscape.mp4" type="video/mp4" />
                      Your browser does not support the video tag.
                    </video>
                  </td>
                </tr>
                <!-- Hyperscape Description -->
                <tr>
                  <td style="padding: 0px 20px 20px 20px; width: 100%; vertical-align: middle;">
                    <a href="https://www.meta.com/experiences/horizon-hyperscape-capture/8866882230015146/">
                      <span class="papertitle">Meta Horizon Hyperscape</span>
                    </a>
                    <br />
                    <strong>Ayush Saraf</strong> (Tech Lead)
                    <br />
                    <em>Launched at Meta Connect</em>, September 2025 &nbsp
                    <br />
                    <p>
                      Technology that lets users scan real-world spaces with Quest headsets and explore them in VR with photorealistic graphics using Gaussian splatting. As Tech Lead since day 0, I led development of the core Gaussian splatting pipeline that powers this experience.
                    </p>
                  </td>
                </tr>
                <!-- YouTube Reviews -->
                <tr>
                  <td style="padding: 0px 20px 20px 20px; width: 100%; vertical-align: middle;">
                    <h3 style="margin-bottom: 10px;">Reviews & Coverage</h3>
                    <div style="display: flex; gap: 20px; flex-wrap: wrap; margin-bottom: 20px;">
                      <iframe width="48%" style="min-width: 300px; aspect-ratio: 16/9;" src="https://www.youtube.com/embed/PBNqTRZprxQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                      <iframe width="48%" style="min-width: 300px; aspect-ratio: 16/9;" src="https://www.youtube.com/embed/OAeYQeEsJsY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                    <p style="margin-top: 10px;">
                      <strong>Press:</strong>
                      <a href="https://techcrunch.com/2025/09/17/meta-launches-hyperscape-technology-to-turn-real-world-spaces-into-vr/">TechCrunch</a> /
                      <a href="https://www.cnet.com/tech/computing/metas-quest-headsets-can-scan-your-home-into-vr-the-results-are-stunning/">CNET</a> /
                      <a href="https://www.uploadvr.com/meta-horizon-hyperscape-photorealistic-scene-capture-quest-3/">UploadVR</a> /
                      <a href="https://skarredghost.com/2024/10/09/meta-hyperscape-review/">The Ghost Howls</a> /
                      <a href="https://gizmodo.com/quest-3-hyperscape-hands-on-capture-test-2000663847">Gizmodo</a>
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <h2>Research</h2>
                    <p>
                      I'm interested in machine learning, computer vision, computer graphics, 3D reconstruction and GenAI. Much of my research revolves around creating 3D worlds by observing real world through images or by interpretting
                      user's imagination via geneative models.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <!-- Textured Gaussians -->
                <tr bgcolor="#ffffd0">
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="textured_gaussians_video">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="https://textured-gaussians.github.io/static/videos/supp/custom-children_art_Ours_1.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://textured-gaussians.github.io/">
                      <span class="papertitle">Textured Gaussians for Enhanced 3D Scene Appearance Modeling</span>
                    </a>
                    <br />
                    Brian Chao, Hung-Yu Tseng, Lorenzo Porzi, Chen Gao, Tuotuo Li, Qinbo Li, <strong>Ayush Saraf</strong>, Jia-Bin Huang, Johannes Kopf, Gordon Wetzstein, Changil Kim
                    <br />
                    <em>CVPR</em>, 2025 &nbsp
                    <br />
                    <a href="https://textured-gaussians.github.io/">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2411.18625">paper</a>
                    <p></p>
                  </td>
                </tr>

                <!-- LTM -->
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="ltm_video">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="https://jh-choi.github.io/LTM/static/images/Example_video.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://jh-choi.github.io/LTM/">
                      <span class="papertitle">LTM: Lightweight Textured Mesh Extraction and Refinement of Large Unbounded Scenes for Efficient Storage and Real-time Rendering</span>
                    </a>
                    <br />
                    Jaehoon Choi, Rajvi Shah, Qinbo Li, Yipeng Wang, <strong>Ayush Saraf</strong>, Changil Kim, Jia-Bin Huang, Dinesh Manocha, Suhib Alsisan, Johannes Kopf
                    <br />
                    <em>CVPR</em>, 2024 &nbsp
                    <br />
                    <a href="https://jh-choi.github.io/LTM/">project page</a>
                    /
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Choi_LTM_Lightweight_Textured_Mesh_Extraction_and_Refinement_of_Large_Unbounded_CVPR_2024_paper.html">paper</a>
                    <p></p>
                  </td>
                </tr>

                <!-- OmnimatteRF -->
                <tr bgcolor="#ffffd0">
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="omnimatte_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/omnimatterf.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <!-- <img src="images/zipnerf.jpg" width="160" /> -->
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://omnimatte-rf.github.io/">
                      <span class="papertitle">OmnimatteRF: Robust Omnimatte with 3D Background Modeling</span>
                    </a>
                    <br />
                    Geng Lin, Chen Gao, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, <strong>Ayush Saraf</strong>
                    <br />
                    <em>ICCV</em>, 2023 &nbsp
                    <br />
                    <a href="https://omnimatte-rf.github.io">project page</a>
                    /
                    <a href="#">video</a>
                    /
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html">paper</a>
                    /
                    <a href="https://github.com/facebookresearch/OmnimatteRF">code</a>
                    <p></p>
                  </td>
                </tr>
                <!-- RoDyNeRF -->
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="rodynerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/rodynerf.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <!-- <img src="images/.jpg" width="160" /> -->
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://robust-dynrf.github.io/">
                      <span class="papertitle">Robust Dynamic Radiance Fields</span>
                    </a>
                    <br />
                    Yu-Lun Liu, Chen Gao, Andreas Meuleman, Hung-Yu Tseng, <strong>Ayush Saraf</strong>, Changil Kim, Yung-Yu Chuang, Johannes Kopf, Jia-Bin Huang
                    <br />
                    <em>CVPR</em>, 2023 &nbsp
                    <br />
                    <a href="https://robust-dynrf.github.io/">project page</a>
                    /
                    <a href="#">video</a>
                    /
                    <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html">paper</a>
                    /
                    <a href="https://github.com/facebookresearch/robust-dynrf">code</a>
                    <p></p>
                  </td>
                </tr>

                <!-- Boosting -->
                <tr>
                <td style="padding: 20px; width: 25%; vertical-align: middle;">
                  <div class="one">
                    <div class="two" id="rodynerf_image">
                      <img src="images/boosting.jpg" width="160" />
                      <!-- <video width="100%" height="100%" muts -->
                    </div>

                  </div>
                </td>
                <td style="padding: 20px; width: 75%; vertical-align: middle;">
                  <a href="https://boosting-view-synth.github.io/">
                    <span class="papertitle">Boosting view synthesis with residual transfer</span>
                  </a>
                  <br />
                  Xuejian Rong,  Jia-Bin Huang,  <strong>Ayush Saraf</strong>,  Changil Kim,  Johannes Kopf
                  <br />
                  <em>CVPR</em>, 2022 &nbsp
                  <br />
                  <a href="https://boosting-view-synth.github.io/">project page</a>
                  /
                  <a href="https://boosting-view-synth.github.io/videos/cvpr_2022_bvs_slides.mp4">video</a>
                  /
                  <a href="https://arxiv.org/abs/2008.12298">paper</a>
                  /
                  <a href="https://github.com/facebookresearch/one_shot_3d_photography">code</a>
                  <p></p>
                </td>
              </tr>


                <!-- DynDyn -->
                <tr bgcolor="#ffffd0">
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="rodynerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/dyndyn.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <!-- <img src="images/.jpg" width="160" /> -->
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://free-view-video.github.io/">
                      <span class="papertitle">Dynamic View Synthesis from Dynamic Monocular Video</span>
                    </a>
                    <br />
                    Chen Gao, <strong>Ayush Saraf</strong>, Johannes Kopf, Jia-Bin Huang
                    <br />
                    <em>ICCV</em>, 2021 &nbsp
                    <br />
                    <a href="https://free-view-video.github.io/">project page</a>
                    /
                    <a href="#">video</a>
                    /
                    <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Gao_Dynamic_View_Synthesis_From_Dynamic_Monocular_Video_ICCV_2021_paper.html">paper</a>
                    /
                    <a href="https://github.com/gaochen315/DynamicNeRF">code</a>
                    <p></p>
                  </td>
                </tr>

                <!-- AMCIO -->
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="rodynerf_image">
                        <!-- <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/photos3d.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video> -->
                      </div>
                      <img src="images/amico.png" width="160" />
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0766.html">
                      <span class="papertitle">AMICO: Amodal Instance Composition</span>
                    </a>
                    <br />
                    Peiye Zhuang, Denis Demandolx, <strong>Ayush Saraf</strong>, Xuejian Rong, Changil Kim and Jia-Bin Huang
                    <br />
                    <em>BMVC</em>, 2021 &nbsp
                    <br />
                    <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0766.html">project page</a>
                    /
                    <a href="https://arxiv.org/abs/2210.05828">paper</a>
                    <p></p>
                  </td>
                </tr>

                <!-- FGVC -->
                <tr bgcolor="#ffffd0">
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="rodynerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/fgvc.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <!-- <img src="images/.jpg" width="160" /> -->
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://free-view-video.github.io/">
                      <span class="papertitle">Flow-edge Guided Video Completion</span>
                    </a>
                    <br />
                    Chen Gao, <strong>Ayush Saraf</strong>, Jia-Bin Huang, Johannes Kopf
                    <br />
                    <em>ECCV</em>, 2020 &nbsp
                    <br />
                    <a href="https://free-view-video.github.io/">project page</a>
                    /
                    <a href="#">video</a>
                    /
                    <a href="hhttps://arxiv.org/abs/2009.01835">paper</a>
                    /
                    <a href="https://github.com/vt-vl-lab/FGVC">code</a>
                    /
                    <a href="https://colab.research.google.com/drive/1pb6FjWdwq_q445rG2NP0dubw7LKNUkqc?usp=sharing">google colab</a>
                    <p></p>
                  </td>
                </tr>

                <!-- 3D Photos -->
                <tr bgcolor="#ffffd0">
                  <td style="padding: 20px; width: 25%; vertical-align: middle;">
                    <div class="one">
                      <div class="two" id="rodynerf_image">
                        <video width="100%" height="100%" muted autoplay loop>
                          <source src="images/photos3d.mp4" type="video/mp4" />
                          Your browser does not support the video tag.
                        </video>
                      </div>
                      <!-- <img src="images/.jpg" width="160" /> -->
                    </div>
                  </td>
                  <td style="padding: 20px; width: 75%; vertical-align: middle;">
                    <a href="https://facebookresearch.github.io/one_shot_3d_photography/">
                      <span class="papertitle">One shot 3d photography</span>
                    </a>
                    <br />
                    Johannes Kopf, Kevin Matzen, Suhib Alsisan, Ocean Quigley, Francis Ge, Yangming Chong, Josh Patterson, Jan-Michael Frahm, Shu Wu, Matthew Yu, Peizhao Zhang, Zijian He, Peter Vajda, <strong>Ayush Saraf</strong>, Michael F. Cohen
                    <br />
                    <em>SIGGRAPH</em>, 2020 &nbsp
                    <br />
                    <a href="https://facebookresearch.github.io/one_shot_3d_photography/">project page</a>
                    /
                    <a href="https://www.youtube.com/watch?v=dR_NGkHS7rU">video</a>
                    /
                    <a href="https://arxiv.org/abs/2008.12298">paper</a>
                    /
                    <a href="https://github.com/facebookresearch/one_shot_3d_photography">code</a>
                    <p></p>
                  </td>
                </tr>
              </tbody>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Miscellanea</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle;"><img src="images/cvf.jpg" /></td>
                  <td width="75%" valign="center">
                    <a href="https://sites.google.com/view/xrnerf/program-committee">Program Committe, XRNeRF CVPR 2023</a>
                    <br />
                    <a href="https://cvpr2023.thecvf.com/">Peer Reviewer, CVPR 2023</a>
                    <br />
                    <a href="https://iccv2023.thecvf.com/">Peer Reviewer, ICCV 2023</a>
                    <br />
                    <a href="https://wacv2023.thecvf.com/">Peer Reviewer, WACV 2023</a>
                    <br />
                    <a href="https://wacv2023.thecvf.com/">Peer Reviewer, WACV 2024</a>
                    <br />
                    Peer Reviewer, IJCV
                    <br />
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 0px;">
                    <br />
                    <p style="text-align: right; font-size: small;">Template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.</p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
