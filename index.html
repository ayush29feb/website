<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

    <title>Ayush Saraf</title>

    <meta name="author" content="Ayush Saraf" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

    <link rel="stylesheet" type="text/css" href="stylesheet.css" />
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>" />
  </head>

  <body>
    <table style="width: 100%; max-width: 1200px; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
      <tbody>
        <tr style="padding: 0px;">
          <td style="padding: 0px;">
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr style="padding: 0px;">
                  <td style="padding: 2.5%; width: 75%; vertical-align: middle;">
                    <p class="name" style="text-align: center;">
                      Ayush Saraf
                    </p>
                    <p>I am a Staff Software Engineer at <a href="https://about.meta.com/realitylabs/">Meta Reality Labs</a> in New York, where I work on Hyperscape and 3D world generation. I build creative tools that help people create 3D worlds‚Äîwhether capturing real spaces or imagining entirely new ones.</p>
                    <p style="text-align: center;">
                      <a href="mailto:ayush29f@gmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=bluhHm8AAAAJ&hl=en">Google Scholar</a>
                      &nbsp;/&nbsp;
                      <a href="https://twitter.com/ayush29feb">Twitter</a> &nbsp;/&nbsp;
                      <a href="https://github.com/ayush29feb/">Github</a>
                    </p>
                  </td>
                  <td style="padding: 2.5%; width: 25%; max-width: 25%;">
                    <a href="images/ayush.png"><img style="width: 100%; max-width: 150px; border-radius: 50%;" alt="profile photo" src="images/ayush.png" class="hoverZoomLink" /></a>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <h2>Hyperscape</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;" bgcolor="#ffffd0">
              <tbody>
                <!-- Hyperscape Featured Video -->
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <video width="100%" style="max-width: 1200px;" muted autoplay loop controls>
                      <source src="images/hyperscape.mp4" type="video/mp4" />
                      Your browser does not support the video tag.
                    </video>
                  </td>
                </tr>
                <!-- Hyperscape Description -->
                <tr>
                  <td style="padding: 0px 20px 20px 20px; width: 100%; vertical-align: middle;">
                    <a href="https://www.meta.com/experiences/horizon-hyperscape-capture/8866882230015146/">
                      <span class="papertitle">Meta Horizon Hyperscape</span>
                    </a>
                    <br />
                    <strong>Ayush Saraf</strong> (Tech Lead)
                    <br />
                    <em>Launched at Meta Connect</em>, September 2025 &nbsp
                    <br />
                    <p>
                      Hyperscape lets you scan real-world spaces with a Quest headset and explore them in VR with photorealistic quality. The technology uses Gaussian splatting to recreate physical environments in virtual reality. As Tech Lead from the start, I led development of the core Gaussian splatting pipeline, tooling, and research infrastructure.
                    </p>
                  </td>
                </tr>
                <!-- YouTube Reviews -->
                <tr>
                  <td style="padding: 0px 20px 20px 20px; width: 100%; vertical-align: middle;">
                    <h3 style="margin-bottom: 10px;">Reviews & Coverage</h3>
                    <div style="display: flex; gap: 20px; flex-wrap: wrap; margin-bottom: 20px;">
                      <iframe width="48%" style="min-width: 300px; aspect-ratio: 16/9;" src="https://www.youtube.com/embed/PBNqTRZprxQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                      <iframe width="48%" style="min-width: 300px; aspect-ratio: 16/9;" src="https://www.youtube.com/embed/OAeYQeEsJsY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
                    </div>
                    <p style="margin-top: 10px;">
                      <strong>Press:</strong>
                      <a href="https://techcrunch.com/2025/09/17/meta-launches-hyperscape-technology-to-turn-real-world-spaces-into-vr/">TechCrunch</a> /
                      <a href="https://www.cnet.com/tech/computing/metas-quest-headsets-can-scan-your-home-into-vr-the-results-are-stunning/">CNET</a> /
                      <a href="https://www.uploadvr.com/meta-horizon-hyperscape-photorealistic-scene-capture-quest-3/">UploadVR</a> /
                      <a href="https://skarredghost.com/2024/10/09/meta-hyperscape-review/">The Ghost Howls</a> /
                      <a href="https://gizmodo.com/quest-3-hyperscape-hands-on-capture-test-2000663847">Gizmodo</a>
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 100%; vertical-align: middle;">
                    <h2>Research</h2>
                    <p>
                      I'm interested in machine learning, computer vision, computer graphics, 3D reconstruction and GenAI. Much of my research revolves around creating 3D worlds by observing real world through images or by interpretting
                      user's imagination via geneative models.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Publications Grid -->
            <div class="pub-grid" style="max-width: 1200px; margin: 0 auto; padding: 0 20px;">

              <!-- Textured Gaussians - Featured -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="https://textured-gaussians.github.io/static/videos/supp/custom-children_art_Ours_1.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://textured-gaussians.github.io/">
                    <span class="papertitle">Textured Gaussians for Enhanced 3D Scene Appearance Modeling</span>
                  </a>
                  <div class="pub-authors">
                    Brian Chao, Hung-Yu Tseng, Lorenzo Porzi, Chen Gao, Tuotuo Li, Qinbo Li, <strong>Ayush Saraf</strong>, Jia-Bin Huang, Johannes Kopf, Gordon Wetzstein, Changil Kim
                  </div>
                  <span class="pub-venue">CVPR 2025</span>
                  <div class="pub-links">
                    <a href="https://textured-gaussians.github.io/">project page</a> /
                    <a href="https://arxiv.org/abs/2411.18625">paper</a>
                  </div>
                </div>
              </div>

              <!-- LTM -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="https://jh-choi.github.io/LTM/static/images/Example_video.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://jh-choi.github.io/LTM/">
                    <span class="papertitle">LTM: Lightweight Textured Mesh Extraction and Refinement of Large Unbounded Scenes for Efficient Storage and Real-time Rendering</span>
                  </a>
                  <div class="pub-authors">
                    Jaehoon Choi, Rajvi Shah, Qinbo Li, Yipeng Wang, <strong>Ayush Saraf</strong>, Changil Kim, Jia-Bin Huang, Dinesh Manocha, Suhib Alsisan, Johannes Kopf
                  </div>
                  <span class="pub-venue">CVPR 2024</span>
                  <div class="pub-links">
                    <a href="https://jh-choi.github.io/LTM/">project page</a> /
                    <a href="https://openaccess.thecvf.com/content/CVPR2024/html/Choi_LTM_Lightweight_Textured_Mesh_Extraction_and_Refinement_of_Large_Unbounded_CVPR_2024_paper.html">paper</a>
                  </div>
                </div>
              </div>

                              <!-- OmnimatteRF -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="images/omnimatterf.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://omnimatte-rf.github.io">
                    <span class="papertitle">OmnimatteRF: Robust Omnimatte with 3D Background Modeling</span>
                  </a>
                  <div class="pub-authors">
                    Geng Lin, Chen Gao, Jia-Bin Huang, Changil Kim, Yipeng Wang, Matthias Zwicker, <strong>Ayush Saraf</strong>
                  </div>
                  <span class="pub-venue">ICCV 2023</span>
                  <div class="pub-links">
                    <a href="https://omnimatte-rf.github.io">project page</a> / <a href="#">video</a> / <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html">paper</a> / <a href="https://github.com/facebookresearch/OmnimatteRF">code</a>
                  </div>
                </div>
              </div>

              <!-- RoDyNeRF -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="images/rodynerf.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://robust-dynrf.github.io/">
                    <span class="papertitle">Robust Dynamic Radiance Fields</span>
                  </a>
                  <div class="pub-authors">
                    Yu-Lun Liu, Chen Gao, Andreas Meuleman, Hung-Yu Tseng, <strong>Ayush Saraf</strong>, Changil Kim, Yung-Yu Chuang, Johannes Kopf, Jia-Bin Huang
                  </div>
                  <span class="pub-venue">CVPR 2023</span>
                  <div class="pub-links">
                    <a href="https://robust-dynrf.github.io/">project page</a> / <a href="#">video</a> / <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Lin_OmnimatteRF_Robust_Omnimatte_with_3D_Background_Modeling_ICCV_2023_paper.html">paper</a> / <a href="https://github.com/facebookresearch/robust-dynrf">code</a>
                  </div>
                </div>
              </div>

              <!-- Boosting -->
              <div class="pub-card">
                <div class="pub-video">
                  <img src="images/boosting.jpg" alt="Boosting view synthesis with residual transfer" />
                </div>
                <div class="pub-content">
                  <a href="https://boosting-view-synth.github.io/">
                    <span class="papertitle">Boosting view synthesis with residual transfer</span>
                  </a>
                  <div class="pub-authors">
                    Xuejian Rong, Jia-Bin Huang, <strong>Ayush Saraf</strong>, Changil Kim, Johannes Kopf
                  </div>
                  <span class="pub-venue">CVPR 2022</span>
                  <div class="pub-links">
                    <a href="https://boosting-view-synth.github.io/">project page</a> / <a href="https://boosting-view-synth.github.io/videos/cvpr_2022_bvs_slides.mp4">video</a> / <a href="https://arxiv.org/abs/2008.12298">paper</a> / <a href="https://github.com/facebookresearch/one_shot_3d_photography">code</a>
                  </div>
                </div>
              </div>

              <!-- DynDyn -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="images/dyndyn.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://free-view-video.github.io/">
                    <span class="papertitle">Dynamic View Synthesis from Dynamic Monocular Video</span>
                  </a>
                  <div class="pub-authors">
                    Chen Gao, <strong>Ayush Saraf</strong>, Johannes Kopf, Jia-Bin Huang
                  </div>
                  <span class="pub-venue">ICCV 2021</span>
                  <div class="pub-links">
                    <a href="https://free-view-video.github.io/">project page</a> / <a href="#">video</a> / <a href="https://openaccess.thecvf.com/content/ICCV2021/html/Gao_Dynamic_View_Synthesis_From_Dynamic_Monocular_Video_ICCV_2021_paper.html">paper</a> / <a href="https://github.com/gaochen315/DynamicNeRF">code</a>
                  </div>
                </div>
              </div>

              <!-- AMICO -->
              <div class="pub-card">
                <div class="pub-video">
                  <img src="images/amico.png" alt="AMICO: Amodal Instance Composition" />
                </div>
                <div class="pub-content">
                  <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0766.html">
                    <span class="papertitle">AMICO: Amodal Instance Composition</span>
                  </a>
                  <div class="pub-authors">
                    Peiye Zhuang, Denis Demandolx, <strong>Ayush Saraf</strong>, Xuejian Rong, Changil Kim and Jia-Bin Huang
                  </div>
                  <span class="pub-venue">BMVC 2021</span>
                  <div class="pub-links">
                    <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0766.html">project page</a> / <a href="https://arxiv.org/abs/2210.05828">paper</a>
                  </div>
                </div>
              </div>

              <!-- FGVC -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="images/fgvc.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://free-view-video.github.io/">
                    <span class="papertitle">Flow-edge Guided Video Completion</span>
                  </a>
                  <div class="pub-authors">
                    Chen Gao, <strong>Ayush Saraf</strong>, Jia-Bin Huang, Johannes Kopf
                  </div>
                  <span class="pub-venue">ECCV 2020</span>
                  <div class="pub-links">
                    <a href="https://free-view-video.github.io/">project page</a> / <a href="#">video</a> / <a href="https://arxiv.org/abs/2009.01835">paper</a> / <a href="https://github.com/vt-vl-lab/FGVC">code</a> / <a href="https://colab.research.google.com/drive/1pb6FjWdwq_q445rG2NP0dubw7LKNUkqc?usp=sharing">google colab</a>
                  </div>
                </div>
              </div>

              <!-- 3D Photos -->
              <div class="pub-card">
                <div class="pub-video">
                  <video muted autoplay loop>
                    <source src="images/photos3d.mp4" type="video/mp4" />
                    Your browser does not support the video tag.
                  </video>
                </div>
                <div class="pub-content">
                  <a href="https://facebookresearch.github.io/one_shot_3d_photography/">
                    <span class="papertitle">One shot 3d photography</span>
                  </a>
                  <div class="pub-authors">
                    Johannes Kopf, Kevin Matzen, Suhib Alsisan, Ocean Quigley, Francis Ge, Yangming Chong, Josh Patterson, Jan-Michael Frahm, Shu Wu, Matthew Yu, Peizhao Zhang, Zijian He, Peter Vajda, <strong>Ayush Saraf</strong>, Michael F. Cohen
                  </div>
                  <span class="pub-venue">SIGGRAPH 2020</span>
                  <div class="pub-links">
                    <a href="https://facebookresearch.github.io/one_shot_3d_photography/">project page</a> / <a href="https://www.youtube.com/watch?v=dR_NGkHS7rU">video</a> / <a href="https://arxiv.org/abs/2008.12298">paper</a> / <a href="https://github.com/facebookresearch/one_shot_3d_photography">code</a>
                  </div>
                </div>
              </div>


            </div>
            <!-- End Publications Grid -->

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tbody>
                <tr>
                  <td>
                    <h2>Miscellanea</h2>
                  </td>
                </tr>
              </tbody>
            </table>
            <table width="100%" align="center" border="0" cellpadding="20">
              <tbody>
                <tr>
                  <td style="padding: 20px; width: 25%; vertical-align: middle;"><img src="images/cvf.jpg" /></td>
                  <td width="75%" valign="center">
                    <a href="https://sites.google.com/view/xrnerf/program-committee">Program Committe, XRNeRF CVPR 2023</a>
                    <br />
                    <a href="https://cvpr2023.thecvf.com/">Peer Reviewer, CVPR 2023</a>
                    <br />
                    <a href="https://iccv2023.thecvf.com/">Peer Reviewer, ICCV 2023</a>
                    <br />
                    <a href="https://wacv2023.thecvf.com/">Peer Reviewer, WACV 2023</a>
                    <br />
                    <a href="https://wacv2023.thecvf.com/">Peer Reviewer, WACV 2024</a>
                    <br />
                    Peer Reviewer, IJCV
                    <br />
                  </td>
                </tr>
              </tbody>
            </table>
            <table style="width: 100%; border: 0px; border-spacing: 0px; border-collapse: separate; margin-right: auto; margin-left: auto;">
              <tbody>
                <tr>
                  <td style="padding: 0px;">
                    <br />
                    <p style="text-align: right; font-size: small;">Template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.</p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
